{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (tuning)\n",
    "**This is the secondary notebook for the LSTM model.** Please refer to *LSTM.ipynb* for the main notebook.\n",
    "\n",
    "In this notebook, we perform a grid search for the permutation of hyperparameters that will give the lowest ```val_loss```. This took extremely long as we not only tested many permutations, but also trained 10 different models per configuration to find the average loss. This was necessary as the building and fitting of LSTM models give volatile results.\n",
    "\n",
    "**We created a separate notebook as the process took about 7 hours to run.**\n",
    "\n",
    "The sections are as follows:\n",
    "1. [Data Importing and Normalization](#1.-Data-Importing-and-Normalization)\n",
    "2. [Functions](#2.-Functions): Helper functions for other sections\n",
    "3. [Early Stopping](#3.-Effect-of-Early-Stopping): Investigation of effect of ```EarlyStopping```\n",
    "3. [Grid Search](#4.-Grid-Search): Actual grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow import keras as keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Importing and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>OpenInt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-09-07</td>\n",
       "      <td>0.42388</td>\n",
       "      <td>0.42902</td>\n",
       "      <td>0.41874</td>\n",
       "      <td>0.42388</td>\n",
       "      <td>23220030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>0.42388</td>\n",
       "      <td>0.42516</td>\n",
       "      <td>0.41366</td>\n",
       "      <td>0.42134</td>\n",
       "      <td>18022532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984-09-11</td>\n",
       "      <td>0.42516</td>\n",
       "      <td>0.43668</td>\n",
       "      <td>0.42516</td>\n",
       "      <td>0.42902</td>\n",
       "      <td>42498199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984-09-12</td>\n",
       "      <td>0.42902</td>\n",
       "      <td>0.43157</td>\n",
       "      <td>0.41618</td>\n",
       "      <td>0.41618</td>\n",
       "      <td>37125801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-09-13</td>\n",
       "      <td>0.43927</td>\n",
       "      <td>0.44052</td>\n",
       "      <td>0.43927</td>\n",
       "      <td>0.43927</td>\n",
       "      <td>57822062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Open     High      Low    Close    Volume  OpenInt\n",
       "0  1984-09-07  0.42388  0.42902  0.41874  0.42388  23220030        0\n",
       "1  1984-09-10  0.42388  0.42516  0.41366  0.42134  18022532        0\n",
       "2  1984-09-11  0.42516  0.43668  0.42516  0.42902  42498199        0\n",
       "3  1984-09-12  0.42902  0.43157  0.41618  0.41618  37125801        0\n",
       "4  1984-09-13  0.43927  0.44052  0.43927  0.43927  57822062        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"aapl.us.txt\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data['Close'] # normal data (non-stationary)\n",
    "diff_data = data['Close'].diff() # stationary data\n",
    "raw_data = raw_data.values.reshape(-1,1)\n",
    "\n",
    "# Perform train:val:test split of 0.6 : 0.2 : 0.2\n",
    "# Input data is stationary\n",
    "split1, split2 = int(len(data)*0.60), int(len(data)*0.80)\n",
    "train_data, val_data, test_data = diff_data[:split1], diff_data[split1:split2], diff_data[split2:]\n",
    "training_set, val_set = train_data.values.reshape(-1,1), val_data.values.reshape(-1,1) # ravel data\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaled_training_set = scaler.fit_transform(training_set)\n",
    "scaled_val_set = scaler.transform(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Data Processing & Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for autoregression\n",
    "def prepare_autoreg(data, timestep, train=True):\n",
    "    x, y = [], []\n",
    "    start = timestep+1 if train else timestep\n",
    "    for i in range(start,len(data)):\n",
    "        x.append(data[i-timestep:i,0])\n",
    "        y.append(data[i,0])\n",
    "    x, y = np.array(x), np.array(y)\n",
    "    x = x.reshape(x.shape[0],x.shape[1],1) # expand 1 dim for LSTM training\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model based on given timestep and number of nodes\n",
    "def build_lstm(timestep, nodes):\n",
    "    lstm = Sequential()\n",
    "    lstm.add(LSTM(nodes, return_sequences=True, input_shape=(timestep,1)))\n",
    "    lstm.add(LSTM(nodes))\n",
    "    lstm.add(Dense(nodes))\n",
    "    lstm.add(Dense(1))\n",
    "    lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(data, step):\n",
    "    (x_train, y_train, x_val, y_val) = data\n",
    "    model = build_lstm(step, 35)\n",
    "    history = model.fit(x_train, y_train, epochs=40, batch_size=32, validation_data=(x_val,y_val), verbose = 0)\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_early(data, step, tolerant):\n",
    "    (x_train, y_train, x_val, y_val) = data\n",
    "    model = build_lstm(step, 35)\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=tolerant)\n",
    "    history = model.fit(x_train, y_train, epochs=40, batch_size=32, validation_data=(x_val,y_val), callbacks=[callback], verbose = 0)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_early_stopping(data, step):\n",
    "    loss_full, loss_early, val_loss_full, val_loss_early = [],[],[],[]\n",
    "    time_full, time_early = [], []\n",
    "    \n",
    "    for tolerant in range(10):\n",
    "        print(tolerant, end=' ')\n",
    "        \n",
    "        # No EarlyStopping\n",
    "        start = time.time()\n",
    "        model, history = LSTM_model(data, step)\n",
    "        end = time.time()\n",
    "        loss_full.append(history.history['loss'][-1]) # final val_loss\n",
    "        val_loss_full.append(history.history['val_loss'][-1]) # final val_loss\n",
    "        time_full.append(end - start)\n",
    "    \n",
    "        # With EarlyStopping\n",
    "        start = time.time()\n",
    "        model_early, history_early = LSTM_model_early(data, step, tolerant)\n",
    "        end = time.time()\n",
    "        loss_early.append(history_early.history['loss'][-1])\n",
    "        val_loss_early.append(history_early.history['val_loss'][-1])\n",
    "        time_early.append(end - start)\n",
    "        \n",
    "    avg_loss_full, avg_loss_early = np.mean(loss_full), np.mean(loss_early)\n",
    "    avg_val_loss_full, avg_val_loss_early = np.mean(val_loss_full), np.mean(val_loss_early)\n",
    "    avg_time_full, avg_time_early = np.mean(time_full), np.mean(time_early)\n",
    "    \n",
    "    print('\\nval_loss (no EarlyStopping):',avg_val_loss_full, ', val_loss (with EarlyStopping):',avg_val_loss_early)\n",
    "    print('loss (no EarlyStopping):',avg_loss_full, ', loss (with EarlyStopping):',avg_loss_early)\n",
    "    print('Time (no EarlyStopping):',avg_time_full, ', Time (with EarlyStopping):',avg_time_early)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model based on given config of [timestep, nodes]\n",
    "def model_fit(config):\n",
    "    timestep, n_nodes = config # unpack config\n",
    "    x_train, y_train = prepare_autoreg(scaled_training_set, timestep, train=True)\n",
    "    x_val, y_val = prepare_autoreg(scaled_val_set, timestep, train=False)\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(units=n_nodes, return_sequences = True, input_shape = (x_train.shape[1],1)))\n",
    "    model.add(keras.layers.LSTM(units=n_nodes))\n",
    "    model.add(keras.layers.Dense(units=n_nodes))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    history = model.fit(x_train, y_train, epochs=40, batch_size=256, verbose=0, callbacks=[callback], validation_data=(x_val,y_val))\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model with the given config and return the final validation loss (MSE)\n",
    "def model_predict(config):\n",
    "    model, history = model_fit(config)\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    return val_loss\n",
    "\n",
    "# Return average loss of 10 models with the same config\n",
    "def repeat_evaluate(config, n_repeats=10):\n",
    "    key = config\n",
    "    scores = [model_predict(config) for _ in range(n_repeats)]\n",
    "    result = np.mean(scores)\n",
    "    print('> Model%s %.9f' % (key, result))\n",
    "    return (key, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of param permutations\n",
    "def model_configs():\n",
    "    # define scope of configs\n",
    "    timestep = [30,35,40,45,50,55,60]\n",
    "    n_nodes = [20,25,30,35,40,45]\n",
    "    \n",
    "    # create configs\n",
    "    configs = [[k,j] for k in timestep for j in n_nodes] \n",
    "    print('Total configs: %d' % len(configs))\n",
    "    return configs\n",
    "\n",
    "# Perform grid search with the given list of param permuations\n",
    "def grid_search(cfg_list):\n",
    "    scores = [repeat_evaluate(cfg) for cfg in cfg_list]\n",
    "    scores.sort(key=lambda tup: tup[1]) # sort configs by error, asc\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Effect of Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 \n",
      "val_loss (no EarlyStopping): 0.03417550846934318 , val_loss (with EarlyStopping): 0.03443170674145222\n",
      "loss (no EarlyStopping): 0.0006339070736430585 , loss (with EarlyStopping): 0.0006309737800620496\n",
      "Time (no EarlyStopping): 147.19956872463226 , Time (with EarlyStopping): 52.568574619293216\n"
     ]
    }
   ],
   "source": [
    "step = 60 # 2 months\n",
    "xtr, ytr = prepare_autoreg(scaled_training_set, step, train=True)\n",
    "xval, yval = prepare_autoreg(scaled_val_set, step, train=False)\n",
    "trial_early_stopping((xtr, ytr, xval, yval), step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences for ```loss``` and ```val_loss``` between training with ```EarlyStopping``` and no ```EarlyStopping``` are very small, but ```EarlyStopping``` is able to save a significant amount of time for training and grid search. Hence, we'll be using ```EarlyStopping``` for all subsequent models to save time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Grid Search\n",
    "In this section, we perform a grid search for the permutation of (timestep, nodes) that gives us the lowest final ```val_loss``` (MSE). In total, we're training 42 × 10 = 420 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following cell took 6 hours to run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configs: 42\n",
      "> Model[[30, 20]] 0.033783221\n",
      "> Model[[30, 25]] 0.033915004\n",
      "> Model[[30, 30]] 0.033942702\n",
      "> Model[[30, 35]] 0.034053292\n",
      "> Model[[30, 40]] 0.034091226\n",
      "> Model[[30, 45]] 0.034064770\n",
      "> Model[[35, 20]] 0.033987318\n",
      "> Model[[35, 25]] 0.033959962\n",
      "> Model[[35, 30]] 0.034036282\n",
      "> Model[[35, 35]] 0.034094409\n",
      "> Model[[35, 40]] 0.034176888\n",
      "> Model[[35, 45]] 0.034173197\n",
      "> Model[[40, 20]] 0.033969628\n",
      "> Model[[40, 25]] 0.034078548\n",
      "> Model[[40, 30]] 0.034147567\n",
      "> Model[[40, 35]] 0.034317990\n",
      "> Model[[40, 40]] 0.034291252\n",
      "> Model[[40, 45]] 0.034310182\n",
      "> Model[[45, 20]] 0.034099816\n",
      "> Model[[45, 25]] 0.034271905\n",
      "> Model[[45, 30]] 0.034289877\n",
      "> Model[[45, 35]] 0.034294938\n",
      "> Model[[45, 40]] 0.034368554\n",
      "> Model[[45, 45]] 0.034424908\n",
      "> Model[[50, 20]] 0.034210833\n",
      "> Model[[50, 25]] 0.034273899\n",
      "> Model[[50, 30]] 0.034368247\n",
      "> Model[[50, 35]] 0.034412097\n",
      "> Model[[50, 40]] 0.034471647\n",
      "> Model[[50, 45]] 0.034488676\n",
      "> Model[[55, 20]] 0.034223896\n",
      "> Model[[55, 25]] 0.034367745\n",
      "> Model[[55, 30]] 0.034460724\n",
      "> Model[[55, 35]] 0.034399272\n",
      "> Model[[55, 40]] 0.034566428\n",
      "> Model[[55, 45]] 0.034589914\n",
      "> Model[[60, 20]] 0.034364055\n",
      "> Model[[60, 25]] 0.034541874\n",
      "> Model[[60, 30]] 0.034599595\n",
      "> Model[[60, 35]] 0.034574867\n",
      "> Model[[60, 40]] 0.034597501\n",
      "> Model[[60, 45]] 0.034721415\n"
     ]
    }
   ],
   "source": [
    "cfg_list = model_configs()\n",
    "scores = grid_search(cfg_list) # grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort the configurations in ascending order of validation loss. Hence, we see that the best configuration is:\n",
    "```timestep=55```, ```nodes=45```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([55, 45], 1.8594361154100626e-05),\n",
       " ([40, 45], 1.908317608467769e-05),\n",
       " ([45, 45], 2.3069215058058034e-05),\n",
       " ([30, 30], 2.4106969158310675e-05),\n",
       " ([55, 40], 2.57116237662558e-05),\n",
       " ([40, 30], 2.623627524371841e-05),\n",
       " ([30, 20], 2.6778622213896597e-05),\n",
       " ([30, 40], 2.7507651520863873e-05),\n",
       " ([30, 45], 2.773977239485248e-05),\n",
       " ([30, 35], 2.7765418781200425e-05),\n",
       " ([45, 30], 3.0388454069907313e-05),\n",
       " ([55, 25], 3.0440280079346847e-05),\n",
       " ([35, 40], 3.111043806711677e-05),\n",
       " ([45, 40], 3.134401686111232e-05),\n",
       " ([60, 35], 3.172740334775881e-05),\n",
       " ([50, 40], 3.178510323778028e-05),\n",
       " ([30, 25], 3.223334015274304e-05),\n",
       " ([35, 20], 3.2875748911465055e-05),\n",
       " ([40, 20], 3.321805406812928e-05),\n",
       " ([45, 35], 3.36800759214384e-05),\n",
       " ([35, 45], 3.3881416857184374e-05),\n",
       " ([60, 45], 3.4214837523904865e-05),\n",
       " ([50, 30], 3.464116753093549e-05),\n",
       " ([40, 35], 3.4682147543207975e-05),\n",
       " ([60, 40], 3.49417562574672e-05),\n",
       " ([50, 45], 3.5890101844415764e-05),\n",
       " ([35, 30], 3.7502321356441824e-05),\n",
       " ([55, 20], 3.8098653294582616e-05),\n",
       " ([60, 30], 3.8156139271450226e-05),\n",
       " ([40, 40], 3.967401607951615e-05),\n",
       " ([35, 35], 3.994302860519383e-05),\n",
       " ([50, 20], 4.014003543488798e-05),\n",
       " ([55, 30], 4.0588925912743434e-05),\n",
       " ([55, 35], 4.082184686922119e-05),\n",
       " ([35, 25], 4.142085599596612e-05),\n",
       " ([45, 25], 4.14332267610007e-05),\n",
       " ([50, 25], 4.175388194198604e-05),\n",
       " ([45, 20], 4.269933751857025e-05),\n",
       " ([50, 35], 4.276345698599471e-05),\n",
       " ([60, 20], 4.516808639891679e-05),\n",
       " ([60, 25], 4.5523329208663196e-05),\n",
       " ([40, 25], 5.0754907169903164e-05)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
